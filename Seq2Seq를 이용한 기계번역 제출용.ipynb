{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc2pgM0w9Xa1"
      },
      "source": [
        "#### **Sequence to Sequence Learning with Neural Networks (NIPS 2014)** 실습\n",
        "* 본 코드는 기본적으로 **Seq2Seq** 논문의 내용을 따릅니다.\n",
        "    * 본 논문은 **딥러닝 기반의 자연어 처리** 기법의 기본적인 구성을 이해하고 공부하는 데에 도움을 줍니다.\n",
        "    * 2020년 기준 가장 뛰어난 번역 모델은 Seq2Seq가 아닌 **Transformer 기반의 모델**입니다.\n",
        "* 코드 실행 전에 **[런타임]** → **[런타임 유형 변경]** → 유형을 **GPU**로 설정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_UOI3Xm4U4M"
      },
      "source": [
        "#### **데이터 전처리(Preprocessing)**\n",
        "\n",
        "* **spaCy 라이브러리**: 문장의 토큰화(tokenization), 태깅(tagging) 등의 전처리 기능을 위한 라이브러리\n",
        "  * 영어(Engilsh)와 독일어(Deutsch) 전처리 모듈 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "x8SEN31g34aX"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s7u-Xt2c4WV8"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "spacy_en = spacy.load(\"en_core_web_sm\") # 영어 토큰화(tokenization)\n",
        "spacy_de = spacy.load(\"de_core_news_sm\") # 독일어 토큰화(tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vnjcXO84aRa",
        "outputId": "9a1baffa-cb02-485b-b6ad-cf70277b433f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "인덱스 0: I\n",
            "인덱스 1: am\n",
            "인덱스 2: a\n",
            "인덱스 3: graduate\n",
            "인덱스 4: student\n",
            "인덱스 5: .\n"
          ]
        }
      ],
      "source": [
        "# 간단히 토큰화(tokenization) 기능 써보기\n",
        "tokenized = spacy_en.tokenizer(\"I am a graduate student.\")\n",
        "\n",
        "for i, token in enumerate(tokenized):\n",
        "    print(f\"인덱스 {i}: {token.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hskqq3f4-YT"
      },
      "source": [
        "* 영어(English) 및 독일어(Deutsch) **토큰화 함수** 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1EH0gEEb4iTj"
      },
      "outputs": [],
      "source": [
        "# 독일어(Deutsch) 문장을 토큰화한 뒤에 순서를 뒤집는 함수\n",
        "def tokenize_de(text):\n",
        "    return [token.text for token in spacy_de.tokenizer(text)][::-1]\n",
        "\n",
        "# 영어(English) 문장을 토큰화 하는 함수\n",
        "def tokenize_en(text):\n",
        "    return [token.text for token in spacy_en.tokenizer(text)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-fAQN1O6_a9"
      },
      "source": [
        "* **필드(field)** 라이브러리를 이용해 데이터셋에 대한 구체적인 전처리 내용을 명시합니다.\n",
        "* 번역 목표\n",
        "    * 소스(SRC): 독일어\n",
        "    * 목표(TRG): 영어"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MVsQFWVmazAM"
      },
      "outputs": [],
      "source": [
        "import torchtext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3MN7tLQ8wzG"
      },
      "source": [
        "* 대표적인 영어-독어 번역 데이터셋인 **Multi30k**를 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkAL7LBJdmzG",
        "outputId": "efd94cf5-2e97-4055-e341-79204f37e361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 27.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 70.4 MB/s \n",
            "\u001b[?25hCollecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1->torchdata) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 67.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2022.6.15)\n",
            "Installing collected packages: urllib3, portalocker, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed portalocker-2.5.1 torchdata-0.4.1 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PaEW2EpY72jt"
      },
      "outputs": [],
      "source": [
        "import torchdata\n",
        "from torchtext.datasets import Multi30k\n",
        "\n",
        "train_dataset = Multi30k(root='.data', split=('train'), language_pair=(\"de\", \"en\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "41tiyqEDeF8N"
      },
      "outputs": [],
      "source": [
        "en = []\n",
        "de = []\n",
        "for label, line in train_dataset:\n",
        "    de+=[tokenize_de(label)]\n",
        "    en+=[tokenize_en(line)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJQmiqRXkn-4",
        "outputId": "351069ae-4d15-4aca-be05-60a847e936e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['Two',\n",
              "  'young',\n",
              "  ',',\n",
              "  'White',\n",
              "  'males',\n",
              "  'are',\n",
              "  'outside',\n",
              "  'near',\n",
              "  'many',\n",
              "  'bushes',\n",
              "  '.'],\n",
              " ['Several',\n",
              "  'men',\n",
              "  'in',\n",
              "  'hard',\n",
              "  'hats',\n",
              "  'are',\n",
              "  'operating',\n",
              "  'a',\n",
              "  'giant',\n",
              "  'pulley',\n",
              "  'system',\n",
              "  '.']]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvPZWqQk9Ea1"
      },
      "source": [
        "* **필드(field)** 객체의 **build_vocab** 메서드를 이용해 영어와 독어의 단어 사전을 생성합니다.\n",
        "  * **최소 2번 이상** 등장한 단어만을 선택합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9JNPXl-QVI6q"
      },
      "outputs": [],
      "source": [
        "sos_token='<sos>'\n",
        "eos_token='<eos>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QUwwB9bMeTNG"
      },
      "outputs": [],
      "source": [
        "TRG=torchtext.vocab.build_vocab_from_iterator(en,min_freq=2,specials=['<pad>','<unk>',sos_token,eos_token])\n",
        "SRC=torchtext.vocab.build_vocab_from_iterator(de,min_freq=2,specials=['<pad>','<unk>',sos_token,eos_token])\n",
        "TRG.set_default_index(1)\n",
        "SRC.set_default_index(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crY-cQsygvyz",
        "outputId": "492a975f-320a-4795-88be-b96e1f6fc09f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6191\n",
            "8014\n"
          ]
        }
      ],
      "source": [
        "print(len(TRG.vocab))\n",
        "print(len(SRC.vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fqxBawjVdnG",
        "outputId": "9540a08b-eea8-4eb7-ab2f-4b8d2d8fa697"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SRC[sos_token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZDT0KF1Vhou",
        "outputId": "daf0affd-1cce-4b22-817f-776592590694"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SRC[eos_token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTST61ysbG-e",
        "outputId": "5fa26a03-6673-41b2-e4d1-510e49308c9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SRC[\"adsafwe\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-B_3ZNMiPap"
      },
      "outputs": [],
      "source": [
        "SRC.vocab.get_stoi()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4PiQ3HR9WKP"
      },
      "source": [
        "* 한 문장에 포함된 단어가 연속적으로 **LSTM**에 입력되어야 합니다.\n",
        "    * 따라서 하나의 배치에 포함된 문장들이 가지는 단어의 개수가 유사하도록 만들면 좋습니다.\n",
        "    * 이를 위해 BucketIterator를 사용합니다.\n",
        "    * **배치 크기(batch size)**: 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "K74YoMgeveVS"
      },
      "outputs": [],
      "source": [
        "def collate_batch(batch):\n",
        "    de_list,en_list=[],[]\n",
        "    for (_de,_en) in batch:\n",
        "        de_list.append(torch.tensor(SRC([sos_token]+tokenize_de(_de)+[eos_token]),dtype=torch.int64))\n",
        "        en_list.append(torch.tensor(TRG([sos_token]+tokenize_en(_en)+[eos_token]),dtype=torch.int64))\n",
        "    inputs=torch.nn.utils.rnn.pad_sequence(de_list+en_list, batch_first=True)\n",
        "    de_inputs = inputs[:len(batch)]\n",
        "    en_inputs = inputs[len(batch):]\n",
        "    return (de_inputs.contiguous(),en_inputs.contiguous())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KM6EVV2t9BHd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator,test_iterator,valid_iterator = iter(Multi30k(root='.data', split=('train','test','valid'), language_pair=(\"de\", \"en\")))\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(train_iterator, batch_size=BATCH_SIZE, shuffle=True,collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_iterator, batch_size=BATCH_SIZE, shuffle=False,collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(valid_iterator, batch_size=BATCH_SIZE,collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b0OshrzwT2J",
        "outputId": "02906b81-970c-4eac-e40a-2b88112051d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[   2,    4,   30,  ...,    0,    0,    0],\n",
            "        [   2,    4,  653,  ...,    0,    0,    0],\n",
            "        [   2,    4,  214,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [   2,    4, 1779,  ...,    0,    0,    0],\n",
            "        [   2,    4,   15,  ...,    0,    0,    0],\n",
            "        [   2,    4, 2962,  ...,    0,    0,    0]])\n",
            "torch.Size([128, 28])\n",
            "tensor([[  2,   6,  16,  ...,   0,   0,   0],\n",
            "        [  2,   6,  51,  ...,   0,   0,   0],\n",
            "        [  2, 431,  36,  ...,   0,   0,   0],\n",
            "        ...,\n",
            "        [  2,   6,  12,  ...,   0,   0,   0],\n",
            "        [  2,   6,  16,  ...,   0,   0,   0],\n",
            "        [  2,   6,  12,  ...,   0,   0,   0]])\n",
            "torch.Size([128, 28])\n"
          ]
        }
      ],
      "source": [
        "# for (i,j) in train_dataloader:\n",
        "#     print(i)\n",
        "#     print(i.shape)\n",
        "#     print(j)\n",
        "#     print(j.shape)\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMJmn_fZmBWG",
        "outputId": "edb4d901-7b6b-4c07-dc31-c1fbb6f83cea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "('Eine Kindergruppe sitzt zusammen und bastelt an etwas.', 'A group of children sit together and work on arts and crafts.')\n",
            "1\n",
            "('Ein asiatischer Mann sitzt auf einer Straße in der Stadt.', 'An Asian man sitting on a city street.')\n",
            "2\n",
            "('Ein Mann kickt einen Football, während im Hintergrund Fans der gegnerischen Mannschaft zuschauen.', 'A man punting a football as fans from the opposing team watch in the background')\n",
            "3\n",
            "('Ein weißer Mann mit Haaren und Bart und einem Kind auf den Schultern.', 'A white man with carrying hair and a beard with a child on his shoulders.')\n",
            "4\n",
            "('Ein Mann steht in einer heruntergekommen wirkenden Gegend.', 'A man stands in a run-down looking area.')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/datapipes/iter/combining.py:249: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  \"the buffer and each child DataPipe will read from the start again.\", UserWarning)\n"
          ]
        }
      ],
      "source": [
        "# cnt=0\n",
        "# a=[]\n",
        "# for i, batch in enumerate(train_iterator):\n",
        "#     a.append(batch)\n",
        "#     print(i)\n",
        "#     print(batch)\n",
        "#     cnt+=1\n",
        "#     if cnt>4:\n",
        "#         break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cr-UGDKCmd-V",
        "outputId": "b656ffa1-6a8b-4691-e9ab-e7c278026aaa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Musiker üben und unter Anleitung eines Dirigenten.'"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# a[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VNXqHZCKm4en",
        "outputId": "551d8541-53b5-4736-ee0a-24db35ac22d0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Musicians are practicing as directed by a director.'"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# a[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j14n9yPMvryi",
        "outputId": "8fd56a86-a1ff-4c7e-c249-e43b2850fb51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[3, 0, 44, 0, 129, 8, 1040, 0]"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# SRC(tokenize_de(a[0][0].lower()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oguDx24e-3Db"
      },
      "source": [
        "#### **인코더(Encoder) 아키텍처**\n",
        "\n",
        "* 주어진 소스 문장을 **문맥 벡터(context vector)로 인코딩**합니다.\n",
        "* LSTM은 hidden state과 cell state을 반환합니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **input_dim**: 하나의 단어에 대한 원핫 인코딩 차원\n",
        "    * **embed_dim**: 임베딩(embedding) 차원\n",
        "    * **hidden_dim**: 히든 상태(hidden state) 차원\n",
        "    * **n_layers**: RNN 레이어의 개수\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Ac28d5DL_ceY"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# 인코더(Encoder) 아키텍처 정의\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim, hidden_dim, n_layers, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        # 임베딩(embedding)은 원-핫 인코딩(one-hot encoding)을 특정 차원의 임베딩으로 매핑하는 레이어\n",
        "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
        "\n",
        "        # LSTM 레이어\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=dropout_ratio)\n",
        "        \n",
        "        # 드롭아웃(dropout)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 인코더는 소스 문장을 입력으로 받아 문맥 벡터(context vector)를 반환        \n",
        "    def forward(self, src):\n",
        "        # src: [단어 개수, 배치 크기]: 각 단어의 인덱스(index) 정보\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded: [단어 개수, 배치 크기, 임베딩 차원]\n",
        "        print(embedded)\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        # outputs: [단어 개수, 배치 크기, 히든 차원]: 현재 단어의 출력 정보\n",
        "        # hidden: [레이어 개수, 배치 크기, 히든 차원]: 현재까지의 모든 단어의 정보\n",
        "        # cell: [레이어 개수, 배치 크기, 히든 차원]: 현재까지의 모든 단어의 정보\n",
        "\n",
        "        # 문맥 벡터(context vector) 반환\n",
        "        return hidden, cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pHj4IlvBzPe"
      },
      "source": [
        "#### **디코더(Decoder) 아키텍처**\n",
        "\n",
        "* 주어진 문맥 벡터(context vector)를 **타겟 문장으로 디코딩**합니다.\n",
        "* LSTM은 hidden state과 cell state을 반환합니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **input_dim**: 하나의 단어에 대한 원핫 인코딩 차원\n",
        "    * **embed_dim**: 임베딩(embedding) 차원\n",
        "    * **hidden_dim**: 히든 상태(hidden state) 차원\n",
        "    * **n_layers**: RNN 레이어의 개수\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fusf6_9yDmfM"
      },
      "outputs": [],
      "source": [
        "# 디코더(Decoder) 아키텍처 정의\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, embed_dim, hidden_dim, n_layers, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        # 임베딩(embedding)은 원-핫 인코딩(one-hot encoding) 말고 특정 차원의 임베딩으로 매핑하는 레이어\n",
        "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
        "\n",
        "        # LSTM 레이어\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=dropout_ratio)\n",
        "        \n",
        "        # FC 레이어 (인코더와 구조적으로 다른 부분)\n",
        "        self.output_dim = output_dim\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "        # 드롭아웃(dropout)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 디코더는 현재까지 출력된 문장에 대한 정보를 입력으로 받아 타겟 문장을 반환     \n",
        "    def forward(self, input, hidden, cell):\n",
        "        # input: [배치 크기]: 단어의 개수는 항상 1개이도록 구현\n",
        "        # hidden: [레이어 개수, 배치 크기, 히든 차원]\n",
        "        # cell = context: [레이어 개수, 배치 크기, 히든 차원]\n",
        "        input = input.unsqueeze(0)\n",
        "        # input: [단어 개수 = 1, 배치 크기]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded: [단어 개수, 배치 크기, 임베딩 차원]\n",
        "\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        # output: [단어 개수 = 1, 배치 크기, 히든 차원]: 현재 단어의 출력 정보\n",
        "        # hidden: [레이어 개수, 배치 크기, 히든 차원]: 현재까지의 모든 단어의 정보\n",
        "        # cell: [레이어 개수, 배치 크기, 히든 차원]: 현재까지의 모든 단어의 정보\n",
        "\n",
        "        # 단어 개수는 어차피 1개이므로 차원 제거\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        # prediction = [배치 크기, 출력 차원]\n",
        "        \n",
        "        # (현재 출력 단어, 현재까지의 모든 단어의 정보, 현재까지의 모든 단어의 정보)\n",
        "        return prediction, hidden, cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j17WxtpJI_9V"
      },
      "source": [
        "#### **Seq2Seq 아키텍처**\n",
        "\n",
        "* 앞서 정의한 인코더(encoder)와 디코더(decoder)를 가지고 있는 하나의 아키텍처입니다.\n",
        "    * **인코더(encoder)**: 주어진 소스 문장을 문맥 벡터(context vector)로 인코딩합니다.\n",
        "    * **디코더(decoder)**: 주어진 문맥 벡터(context vector)를 타겟 문장으로 디코딩합니다.\n",
        "    * 단, **디코더는 한 단어씩** 넣어서 한 번씩 결과를 구합니다.\n",
        "* **Teacher forcing**: 디코더의 예측(prediction)을 다음 입력으로 사용하지 않고, 실제 목표 출력(ground-truth)을 다음 입력으로 사용하는 기법"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vsA6C6B5Glhc"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    # 학습할 때는 완전한 형태의 소스 문장, 타겟 문장, teacher_forcing_ratio를 넣기\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        # src: [단어 개수, 배치 크기]\n",
        "        # trg: [단어 개수, 배치 크기]\n",
        "        # 먼저 인코더를 거쳐 문맥 벡터(context vector)를 추출\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        # 디코더(decoder)의 최종 결과를 담을 텐서 객체 만들기\n",
        "        trg_len = trg.shape[0] # 단어 개수\n",
        "        batch_size = trg.shape[1] # 배치 크기\n",
        "        trg_vocab_size = self.decoder.output_dim # 출력 차원\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        # 첫 번째 입력은 항상 <sos> 토큰\n",
        "        input = trg[0, :]\n",
        "\n",
        "        # 타겟 단어의 개수만큼 반복하여 디코더에 포워딩(forwarding)\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "\n",
        "            outputs[t] = output # FC를 거쳐서 나온 현재의 출력 단어 정보\n",
        "            top1 = output.argmax(1) # 가장 확률이 높은 단어의 인덱스 추출\n",
        "\n",
        "            # teacher_forcing_ratio: 학습할 때 실제 목표 출력(ground-truth)을 사용하는 비율\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            input = trg[t] if teacher_force else top1 # 현재의 출력 결과를 다음 입력에서 넣기\n",
        "        \n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyXRWyDrHYSB"
      },
      "source": [
        "#### **학습(Training)**\n",
        "\n",
        "* 하이퍼 파라미터 설정 및 모델 초기화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qVsGIVvzMZ-N"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENCODER_EMBED_DIM = 256\n",
        "DECODER_EMBED_DIM = 256\n",
        "HIDDEN_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT_RATIO = 0.5\n",
        "DEC_DROPOUT_RATIO = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0WM3urPiIE1T"
      },
      "outputs": [],
      "source": [
        "# 인코더(encoder)와 디코더(decoder) 객체 선언\n",
        "enc = Encoder(INPUT_DIM, ENCODER_EMBED_DIM, HIDDEN_DIM, N_LAYERS, ENC_DROPOUT_RATIO)\n",
        "dec = Decoder(OUTPUT_DIM, DECODER_EMBED_DIM, HIDDEN_DIM, N_LAYERS, DEC_DROPOUT_RATIO)\n",
        "\n",
        "# Seq2Seq 객체 선언\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcnWnXGIMwHk"
      },
      "source": [
        "* 논문의 내용대로 $\\mathcal{U}(-0.08, 0.08)$의 값으로 **모델 가중치 파라미터 초기화**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdfqma4uMaoI",
        "outputId": "5a41e3cf-d8fb-42ac-8d0b-7047c6762605"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(8014, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(6191, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=6191, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQUwj0UgIS6E"
      },
      "source": [
        "* 학습 및 평가 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "BeqqI7xfM71V"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Adam optimizer로 학습 최적화\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
        "TRG_PAD_IDX = TRG[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SXo7ZOclNG2-"
      },
      "outputs": [],
      "source": [
        "# 모델 학습(train) 함수\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train() # 학습 모드\n",
        "    epoch_loss = 0\n",
        "    count=0\n",
        "    # 전체 학습 데이터를 확인하며\n",
        "    for src,trg in iterator:\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        count+=src.shape[0]\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "        # output: [출력 단어 개수, 배치 크기, 출력 차원]\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        # 출력 단어의 인덱스 0은 사용하지 않음\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        # output = [(출력 단어의 개수 - 1) * batch size, output dim]\n",
        "        trg = trg[1:].view(-1)\n",
        "        # trg = [(타겟 단어의 개수 - 1) * batch size]\n",
        "        \n",
        "        # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward() # 기울기(gradient) 계산\n",
        "        \n",
        "        # 기울기(gradient) clipping 진행\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        # 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "        \n",
        "        # 전체 손실 값 계산\n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    \n",
        "    return epoch_loss / count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DzR8hm9HQ1gb"
      },
      "outputs": [],
      "source": [
        "# 모델 평가(evaluate) 함수\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval() # 평가 모드\n",
        "    epoch_loss = 0\n",
        "    count=0\n",
        "    with torch.no_grad():\n",
        "        # 전체 평가 데이터를 확인하며\n",
        "        for src,trg in iterator:\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "            \n",
        "            count+=src.shape[0]\n",
        "            # 평가할 때 teacher forcing는 사용하지 않음\n",
        "            output = model(src, trg, 0)\n",
        "            # output: [출력 단어 개수, 배치 크기, 출력 차원]\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            # 출력 단어의 인덱스 0은 사용하지 않음\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            # output = [(출력 단어의 개수 - 1) * batch size, output dim]\n",
        "            trg = trg[1:].view(-1)\n",
        "            # trg = [(타겟 단어의 개수 - 1) * batch size]\n",
        "\n",
        "            # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            # 전체 손실 값 계산\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76X7pR1cLtAl"
      },
      "source": [
        "* 학습(training) 및 검증(validation) 진행\n",
        "    * **학습 횟수(epoch)**: 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "iVGWe9VtSwx0"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMMkAnGeSyMW",
        "outputId": "48e6239f-0147-4693-e25e-d0850c25bd20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 1m 28s\n",
            "\tTrain Loss: 0.041 | Train PPL: 1.042\n",
            "\tValidation Loss: 0.037 | Validation PPL: 1.038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/datapipes/iter/combining.py:249: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  \"the buffer and each child DataPipe will read from the start again.\", UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 02 | Time: 1m 27s\n",
            "\tTrain Loss: 0.037 | Train PPL: 1.038\n",
            "\tValidation Loss: 0.039 | Validation PPL: 1.039\n",
            "Epoch: 03 | Time: 1m 27s\n",
            "\tTrain Loss: 0.037 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.037 | Validation PPL: 1.038\n",
            "Epoch: 04 | Time: 1m 28s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.037 | Validation PPL: 1.037\n",
            "Epoch: 05 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.037 | Validation PPL: 1.037\n",
            "Epoch: 06 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.037 | Validation PPL: 1.037\n",
            "Epoch: 07 | Time: 1m 28s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.036 | Validation PPL: 1.037\n",
            "Epoch: 08 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.036 | Validation PPL: 1.037\n",
            "Epoch: 09 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.036 | Validation PPL: 1.037\n",
            "Epoch: 10 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.037 | Validation PPL: 1.037\n",
            "Epoch: 11 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.037 | Validation PPL: 1.037\n",
            "Epoch: 12 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.036 | Validation PPL: 1.037\n",
            "Epoch: 13 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.037 | Validation PPL: 1.038\n",
            "Epoch: 14 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.036 | Validation PPL: 1.037\n",
            "Epoch: 15 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.036 | Validation PPL: 1.037\n",
            "Epoch: 16 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.036 | Validation PPL: 1.037\n",
            "Epoch: 17 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.036 | Validation PPL: 1.037\n",
            "Epoch: 18 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.037 | Validation PPL: 1.037\n",
            "Epoch: 19 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.036 | Validation PPL: 1.037\n",
            "Epoch: 20 | Time: 1m 27s\n",
            "\tTrain Loss: 0.036 | Train PPL: 1.037\n",
            "\tValidation Loss: 0.036 | Validation PPL: 1.037\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import math\n",
        "import random\n",
        "\n",
        "N_EPOCHS = 20\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time() # 시작 시간 기록\n",
        "\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_dataloader, criterion)\n",
        "\n",
        "    end_time = time.time() # 종료 시간 기록\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'seq2seq.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
        "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "OvYlZ85ZRUya",
        "outputId": "b8dafca6-78f6-4d7d-fc34-566707ced9d5"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f87472d9-d8a6-41cd-8dd8-d41b6d5ccd3a\", \"seq2seq.pt\", 56674839)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 학습된 모델 저장\n",
        "from google.colab import files\n",
        "\n",
        "files.download('seq2seq.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6d2isoPL_P0"
      },
      "source": [
        "#### **모델 최종 테스트(testing) 결과 확인**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rfs5GYSpUGeU"
      },
      "outputs": [],
      "source": [
        "!wget https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/ERgwTMYWR7FMhApROaNvZREBTjEDi00ttSzt8ZNj1PS_5g?download=1 -O seq2seq.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co3YMQ2NS0Ia",
        "outputId": "c7332098-4675-4978-a39d-536999b92ba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.037 | Test PPL: 1.038\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('seq2seq.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_dataloader, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMvcdNR7YqAo"
      },
      "source": [
        "#### **나만의 데이터로 모델 사용해보기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OjHJkeznS1oS"
      },
      "outputs": [],
      "source": [
        "# 번역(translation) 함수\n",
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\n",
        "    model.eval() # 평가 모드\n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load(\"de_core_news_sm\")\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # 처음에 <sos> 토큰, 마지막에 <eos> 토큰 붙이기\n",
        "    tokens = [sos_token] +tokens + [eos_token]\n",
        "    print(f\"전체 소스 토큰: {tokens}\")\n",
        "\n",
        "    src_indexes = src_field(tokens)\n",
        "    print(f\"소스 문장 인덱스: {src_indexes}\")\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    # 인코더(endocer)에 소스 문장을 넣어 문맥 벡터(context vector) 계산\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    # 처음에는 <sos> 토큰 하나만 가지고 있도록 하기\n",
        "    trg_indexes = [trg_field[sos_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "        # 이전에 출력한 단어가 현재 단어로 입력될 수 있도록\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token) # 출력 문장에 더하기\n",
        "\n",
        "        # <eos>를 만나는 순간 끝\n",
        "        if pred_token == trg_field[eos_token]:\n",
        "            break\n",
        "\n",
        "    # 각 출력 단어 인덱스를 실제 단어로 변환\n",
        "    trg_tokens = trg_field.lookup_tokens(trg_indexes)\n",
        "\n",
        "    # 첫 번째 <sos>는 제외하고 출력 문장 반환\n",
        "    return trg_tokens[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OSgbkh0Vkq7",
        "outputId": "174b7d65-c7e5-444e-8541-dc05faaefbc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "소스 문장: Mehrere Menschen stehen in der Dämmerung in der Nähe einiger Bäume.\n",
            "타겟 문장: Several people are standing near trees at dusk.\n",
            "전체 소스 토큰: ['<sos>', 'mehrere', 'menschen', 'stehen', 'in', 'der', 'dämmerung', 'in', 'der', 'nähe', 'einiger', 'bäume', '.', '<eos>']\n",
            "소스 문장 인덱스: [2, 412, 1, 53, 7, 16, 1, 7, 16, 1, 2450, 1, 4, 3]\n",
            "모델 출력 결과: a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a\n"
          ]
        }
      ],
      "source": [
        "example_idx = 102\n",
        "\n",
        "train_iterator,test_iterator,valid_iterator = iter(Multi30k(root='.data', split=('train','test','valid'), language_pair=(\"de\", \"en\")))\n",
        "cnt=0\n",
        "for src,trg in valid_iterator:\n",
        "    cnt+=1\n",
        "    if cnt>example_idx:\n",
        "        break\n",
        "\n",
        "\n",
        "print(f'소스 문장: {src}')\n",
        "print(f'타겟 문장: {trg}')\n",
        "print(\"모델 출력 결과:\", \" \".join(translate_sentence(src, SRC, TRG, model, device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR4mSubPXOJV",
        "outputId": "80227c66-cc5b-4455-de4a-b27b096c10a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "소스 문장: ['.', 'Abend', 'Guten']\n",
            "전체 소스 토큰: ['<sos>', '.', 'abend', 'guten', '<eos>']\n",
            "소스 문장 인덱스: [2, 4, 1, 4172, 3]\n",
            "모델 출력 결과: a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a\n"
          ]
        }
      ],
      "source": [
        "src = tokenize_de(\"Guten Abend.\")\n",
        "\n",
        "print(f'소스 문장: {src}')\n",
        "print(\"모델 출력 결과:\", \" \".join(translate_sentence(src, SRC, TRG, model, device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXtjjCsAHJX9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
